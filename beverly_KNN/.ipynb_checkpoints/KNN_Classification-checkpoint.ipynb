{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data set: https://www.kaggle.com/uciml/mushroom-classification\n",
    "#### Name: Beverly Hom, 820921134\n",
    "#### CS 596: Machine Learning\n",
    "#### Fall 2017\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised Classification \n",
    "#### Algorithm 1: K-Nearest Neighbor\n",
    "- Element classified by a majority vote of its nearest neighbors \n",
    "- Output is class membership "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'caret'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-d9e3eb23fe58>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatches\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmpatches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msklearn\u001b[0m \u001b[0;31m# machine learning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcaret\u001b[0m \u001b[0;31m# machine learning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m \u001b[0;31m# plotting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpylab\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'caret'"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import pandas as pd # data frames\n",
    "import numpy as np # numerical matrices\n",
    "import matplotlib # plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import sklearn # machine learning \n",
    "import caret # machine learning \n",
    "import seaborn as sns # plotting\n",
    "import pylab as pl\n",
    "import mlxtend\n",
    "sns.set(color_codes = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set plotting parameters \n",
    "\n",
    "sns.set_context('paper')\n",
    "sns.set(style='whitegrid', rc={'grid.linestyle':':', 'axes.titlesize':16, \n",
    "                               'axes.labelsize':16, 'xtick.labelsize':16,\n",
    "                            'ytick.labelsize':14, 'figure.figsize':(8,6), \n",
    "                              'legend.fontsize':12})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load in csv file\n",
    "\n",
    "file = \"/Users/beverly/mushroom_classification/mushrooms.csv\"\n",
    "\n",
    "# Read in csv files as pandas dataframes \n",
    "df = pd.read_csv(file)\n",
    "#print(type(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get matrix dimensions\n",
    "print(\"Data dimensions: {}\".format(df.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View Raw Categorical Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Data description:\")\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the first 5 rows \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dataframe to matrix\n",
    "data_matrix = df.as_matrix()\n",
    "\n",
    "#print(type(matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counts of features \n",
    "#df.apply(pd.value_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Categorical Data to Numerical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use label encoder to convert categorical labels to numerical labels\n",
    "\n",
    "from sklearn import preprocessing \n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "transformed_matrix = df.apply(label_encoder.fit_transform)\n",
    "\n",
    "# View transformed matrix \n",
    "#df.apply(label_encoder.fit_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dichotimize Classes by \"Class\" Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dichotimize classes \n",
    "# e = ediible = class 0 \n",
    "# p = poisonous = class 1\n",
    "\n",
    "# Class 0: Edible class of mushrooms \n",
    "class0 = transformed_matrix.loc[transformed_matrix['class'] == 0]\n",
    "\n",
    "# View class0 matrix \n",
    "class0.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class 1: Poisonous class of mushrooms\n",
    "class1 = transformed_matrix.loc[transformed_matrix['class'] == 1]\n",
    "\n",
    "# View class1 matrix \n",
    "class1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution of \"Edible\" Class (Class 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distrubtion of edible class\n",
    "# Try plotting in matplotlib\n",
    "\n",
    "# New figure size\n",
    "fig_size[0] = 20\n",
    "fig_size[1] = 20\n",
    "plt.rcParams[\"figure.figsize\"] = fig_size\n",
    "\n",
    "class0.hist()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution of \"Poisonous Class (Class 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of poisonous class \n",
    "class1.hist(color = \"red\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heatmap: Correlation Matrix of Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot correlation matrix as heatmap\n",
    "\n",
    "# Remove the \"veil-type\"column\n",
    "t_matrix = transformed_matrix.drop(\"veil-type\", axis = 1) \n",
    "t_matrix = t_matrix.drop(\"class\", axis = 1)\n",
    "sns.heatmap(t_matrix.corr(), annot = True, fmt = \"0.2f\")\n",
    "\n",
    "# New figure size\n",
    "fig_size[0] = 50\n",
    "fig_size[1] = 20\n",
    "plt.rcParams[\"figure.figsize\"] = fig_size\n",
    "\n",
    "plt.show()\n",
    "# Double click on image to make larger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename matrix variables for splitting into training and testing sets\n",
    "\n",
    "X = transformed_matrix.drop(\"class\", axis = 1)\n",
    "y = transformed_matrix[\"class\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Data into 70% Training, 30% Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing set \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split into 70% training and 30% testing data \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, random_state = 40)\n",
    "\n",
    "print(\"Training set matrix dimensions: {}\".format(X_train.shape))\n",
    "print(\"Training set label  dimensions: {}\".format(y_train.shape))\n",
    "print(\"\\n\")\n",
    "print(\"Testing set matrix dimensions: {}\".format(X_test.shape))\n",
    "print(\"Testing set label dimensions: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Algorithm: K-Nearest Neighbors "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1:  metric = euclidean, weight = distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Test many k values \n",
    "k_values = [1, 3, 5, 7, 9, 11, 13, 15, 17, 21, 23, 25, 27, 31]\n",
    "print(\"Number of k values: {}\".format(len(k_values)))\n",
    "\n",
    "# Create en empty list to store all data\n",
    "models = []\n",
    "test_predictions = []\n",
    "train_predictions = []\n",
    "confusion_matrices = []\n",
    "class_reports = []\n",
    "acc_scores = []\n",
    "acc_trainscores = []\n",
    "\n",
    "error_scores = []\n",
    "error_scores = []\n",
    "cv_train_scores = []\n",
    "cv_train_means = []\n",
    "cv_train_acc = []\n",
    "cv_test_scores = []\n",
    "cv_test_means = []\n",
    "cv_test_acc = []\n",
    "\n",
    "   \n",
    "for k in k_values:\n",
    "    model = KNeighborsClassifier(n_neighbors = k, metric = \"euclidean\", weights = \"distance\")\n",
    "    models.append(model)\n",
    "print(\"KNN Models:\")\n",
    "for model in models:\n",
    "    print(model)\n",
    "\n",
    "# Fit the model- learn from training set \n",
    "for model in models:\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "# Predict responses on the testing set \n",
    "for model in models:\n",
    "    test_pred = model.predict(X_test)\n",
    "    test_predictions.append(test_pred)\n",
    "    \n",
    "# Predict responses on the training set \n",
    "for model in models:\n",
    "    train_pred = model.predict(X_train)\n",
    "    train_predictions.append(train_pred)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Confusion Matrices:\")\n",
    "\n",
    "# Create confusion matrices for each model \n",
    "for test_pred in test_predictions:\n",
    "    c_matrix = confusion_matrix(y_test, test_pred)\n",
    "    confusion_matrices.append(c_matrix)\n",
    "for c_matrix in confusion_matrices:\n",
    "    print(c_matrix)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Classification Reports:\")\n",
    "    \n",
    "# Create a classificaiton report for each model \n",
    "targets = [\"Edible\", \"Poisonous\"]\n",
    "for test_pred in test_predictions: \n",
    "    report = classification_report(y_test, test_pred, target_names = targets)\n",
    "    class_reports.append(report)\n",
    "for report in class_reports:\n",
    "    print(report)\n",
    "    \n",
    "print(\"\\n\")\n",
    "print(\"Testing Accuracy Scores:\")\n",
    "\n",
    "# Compute the testing accuracy for each model \n",
    "for test_pred in test_predictions:\n",
    "    acc = accuracy_score(y_test, test_pred)\n",
    "    acc_scores.append(acc*100)\n",
    "for acc in acc_scores:\n",
    "    print(acc)\n",
    "    \n",
    "print(\"\\n\")\n",
    "print(\"Training Accuracy Scores:\")\n",
    "\n",
    "# Compute the training accuracy for each model \n",
    "for train_pred in train_predictions:\n",
    "    acc = accuracy_score(y_train, train_pred)\n",
    "    acc_trainscores.append(acc*100)\n",
    "for acc in acc_trainscores:\n",
    "    print(acc)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "print(\"\\n\")\n",
    "print(\"Error Scores:\")\n",
    "    \n",
    "    \n",
    "# Compute the testing error for each model \n",
    "for acc in acc_scores:\n",
    "    error = (100 - acc)\n",
    "    error_scores.append(error)\n",
    "for error in error_scores:\n",
    "    print(error)\n",
    "    \n",
    "\n",
    "    \n",
    "# Compute the training accuracy for each model \n",
    "#for train_pred in train_predictions:\n",
    "#    train_acc = accuracy_score(y_train, train_pred)\n",
    "#    train_acc_scores.append(train_acc)\n",
    "    \n",
    "\n",
    "    \n",
    "# Perform 10-fold CV to get training and testing scores\n",
    "for model in models:\n",
    "    cv_results = cross_validate(model, X, y, cv = 10, return_train_score = True)\n",
    "    train_score = cv_results[\"train_score\"]\n",
    "    cv_train_scores.append(train_score)\n",
    "    test_score = cv_results[\"test_score\"]\n",
    "    cv_test_scores.append(test_score)\n",
    "    \n",
    "print(\"\\n\")\n",
    "print(\"10-fold CV train scores:\")\n",
    "    \n",
    "for train_score in cv_train_scores:\n",
    "    print(train_score)\n",
    "    \n",
    "print(\"\\n\")\n",
    "print(\"10-fold CV test score:\")\n",
    "for test_score in cv_test_scores:\n",
    "    print(test_score)\n",
    "    \n",
    "\n",
    "#print(\"\\n\")\n",
    "#print(\"10-fold training averages\")\n",
    "# Get means and standard dev from 10-fold CVs\n",
    "for train_score in cv_train_scores:\n",
    "    mean = train_score.mean()\n",
    "    cv_train_means.append(mean)\n",
    "#for mean in cv_train_means:\n",
    "#    print(mean)\n",
    "    \n",
    "    \n",
    "print(\"\\n\") \n",
    "print(\"10-fold testing averages\")\n",
    "\n",
    "for test_score in cv_test_scores:\n",
    "    mean = test_score.mean()\n",
    "    cv_test_means.append(mean*100)\n",
    "for mean in cv_test_means:\n",
    "    print(mean)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make figure sizes larger\n",
    "\n",
    "# New figure size\n",
    "fig_size[0] = 7\n",
    "fig_size[1] = 7\n",
    "plt.rcParams[\"figure.figsize\"] = fig_size\n",
    "\n",
    "plt.plot(k_values, acc_scores, linewidth = 4.0)\n",
    "\n",
    "plt.title(\"Classification Accuracy with Increasing K-Values\", fontsize = 20)\n",
    "plt.ylabel(\"Accuracy\", fontsize = 20)\n",
    "plt.xlabel(\"K-value\", fontsize = 20)\n",
    "plt.tick_params(axis = \"both\", which = \"major\", labelsize = 15)\n",
    "\n",
    "#plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make figure sizes larger\n",
    "\n",
    "#lines = plt.plot(acc_scores, train_acc_scores)\n",
    "\n",
    "# Get current figure size \n",
    "fig_size = plt.rcParams[\"figure.figsize\"] \n",
    "# print(\"Current size: {}\".format(fig_size)) \n",
    "\n",
    "# New figure size\n",
    "fig_size[0] = 7\n",
    "fig_size[1] = 7\n",
    "plt.rcParams[\"figure.figsize\"] = fig_size\n",
    "\n",
    "plt.title(\"Classification Error with Increasing K-Values\", fontsize = 20)\n",
    "plt.ylabel(\"Error\", fontsize = 20)\n",
    "plt.xlabel(\"K-value\", fontsize = 20)\n",
    "plt.tick_params(axis = \"both\", which = \"major\", labelsize = 15)\n",
    "plt.plot(k_values, error_scores, linewidth = 4.0, color = \"red\")\n",
    "\n",
    "\n",
    "#plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_test_means \n",
    "\n",
    "num_models = list(range(1,15))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set plotting parameters for seaborn \n",
    "\n",
    "sns.set_context('paper')\n",
    "sns.set(style='whitegrid', rc={'grid.linestyle':':', 'axes.titlesize':16, \n",
    "                               'axes.labelsize':16, 'xtick.labelsize':16,\n",
    "                               'ytick.labelsize':14, 'figure.figsize':(8,6), \n",
    "                               'legend.fontsize':12})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# New figure size\n",
    "fig_size[0] = 15\n",
    "fig_size[1] = 12\n",
    "plt.rcParams[\"figure.figsize\"] = fig_size\n",
    "\n",
    "# For x-axis values \n",
    "cv_axis = list(range(1,11))\n",
    "\n",
    "# Lines to plot\n",
    "plt.plot(k_values, acc_scores, color = \"orange\", linewidth = 4.0, label = \"Testing Accuracy\")\n",
    "plt.plot(k_values, acc_trainscores, color = \"purple\", linewidth = 4.0, label = \"Training Accuracy\")\n",
    "plt.plot(k_values, cv_test_means, color = \"green\", linewidth = 4.0, label = \"10-Fold CV Accuracy\")\n",
    "\n",
    "# Plotting settings \n",
    "plt.title(\"Model 1: K-Nearest Neighbor (metric: euclidean, weight: distance)\", fontsize = 27)\n",
    "plt.ylabel(\"Accuracy\", fontsize = 25)\n",
    "plt.xlabel(\"K-Value\", fontsize = 25)\n",
    "plt.tick_params(axis = \"both\", which = \"major\", labelsize = 20)\n",
    "\n",
    "#ax.legend(handles, labels)\n",
    "plt.legend(fontsize = 20)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2: KNN (metric = minkowski, weight = uniform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test many k values \n",
    "k_values = [1, 3, 5, 7, 9, 11, 13, 15, 17, 21, 23, 25, 27, 31]\n",
    "print(\"Number of k values: {}\".format(len(k_values)))\n",
    "\n",
    "# Create en empty list to store all data\n",
    "models = []\n",
    "test_predictions = []\n",
    "train_predictions = []\n",
    "confusion_matrices = []\n",
    "class_reports = []\n",
    "acc_scores = []\n",
    "acc_trainscores = []\n",
    "error_scores = []\n",
    "error_scores = []\n",
    "cv_train_scores = []\n",
    "cv_train_means = []\n",
    "cv_train_acc = []\n",
    "cv_test_scores = []\n",
    "cv_test_means = []\n",
    "cv_test_acc = []\n",
    "\n",
    "   \n",
    "for k in k_values:\n",
    "    model = KNeighborsClassifier(n_neighbors = k, metric = \"minkowski\", weights = \"uniform\")\n",
    "    models.append(model)\n",
    "print(\"KNN Models:\")\n",
    "for model in models:\n",
    "    print(model)\n",
    "\n",
    "# Fit the model- learn from training set \n",
    "for model in models:\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "# Predict responses on the testing set \n",
    "for model in models:\n",
    "    test_pred = model.predict(X_test)\n",
    "    test_predictions.append(test_pred)\n",
    "    \n",
    "# Predict responses on the training set \n",
    "for model in models:\n",
    "    train_pred = model.predict(X_train)\n",
    "    train_predictions.append(train_pred)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Confusion Matrices:\")\n",
    "\n",
    "# Create confusion matrices for each model \n",
    "for test_pred in test_predictions:\n",
    "    c_matrix = confusion_matrix(y_test, test_pred)\n",
    "    confusion_matrices.append(c_matrix)\n",
    "for c_matrix in confusion_matrices:\n",
    "    print(c_matrix)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Classification Reports:\")\n",
    "    \n",
    "# Create a classificaiton report for each model \n",
    "targets = [\"Edible\", \"Poisonous\"]\n",
    "for test_pred in test_predictions: \n",
    "    report = classification_report(y_test, test_pred, target_names = targets)\n",
    "    class_reports.append(report)\n",
    "for report in class_reports:\n",
    "    print(report)\n",
    "    \n",
    "print(\"\\n\")\n",
    "print(\"Testing Accuracy Scores:\")\n",
    "\n",
    "# Compute the testing accuracy for each model \n",
    "for test_pred in test_predictions:\n",
    "    acc = accuracy_score(y_test, test_pred)\n",
    "    acc_scores.append(acc*100)\n",
    "for acc in acc_scores:\n",
    "    print(acc)\n",
    "    \n",
    "print(\"\\n\")\n",
    "print(\"Training Accuracy Scores:\")\n",
    "\n",
    "for train_pred in train_predictions:\n",
    "    acc = accuracy_score(y_train, train_pred)\n",
    "    acc_trainscores.append(acc*100)\n",
    "for acc in acc_trainscores:\n",
    "    print(acc)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "print(\"\\n\")\n",
    "print(\"Error Scores:\")\n",
    "    \n",
    "    \n",
    "# Compute the testing error for each model \n",
    "for acc in acc_scores:\n",
    "    error = (100 - acc)\n",
    "    error_scores.append(error)\n",
    "for error in error_scores:\n",
    "    print(error)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "# Perform 10-fold CV to get training and testing scores\n",
    "for model in models:\n",
    "    cv_results = cross_validate(model, X, y, cv = 10, return_train_score = True)\n",
    "    train_score = cv_results[\"train_score\"]\n",
    "    cv_train_scores.append(train_score)\n",
    "    test_score = cv_results[\"test_score\"]\n",
    "    cv_test_scores.append(test_score)\n",
    "    \n",
    "print(\"\\n\")\n",
    "print(\"10-fold CV train scores:\")\n",
    "    \n",
    "for train_score in cv_train_scores:\n",
    "    print(train_score)\n",
    "    \n",
    "print(\"\\n\")\n",
    "print(\"10-fold CV test score:\")\n",
    "for test_score in cv_test_scores:\n",
    "    print(test_score)\n",
    "    \n",
    "\n",
    "#print(\"\\n\")\n",
    "#print(\"10-fold training averages\")\n",
    "# Get means and standard dev from 10-fold CVs\n",
    "for train_score in cv_train_scores:\n",
    "    mean = train_score.mean()\n",
    "    cv_train_means.append(mean)\n",
    "#for mean in cv_train_means:\n",
    "#    print(mean)\n",
    "    \n",
    "    \n",
    "print(\"\\n\") \n",
    "print(\"10-fold testing averages\")\n",
    "\n",
    "for test_score in cv_test_scores:\n",
    "    mean = test_score.mean()\n",
    "    cv_test_means.append(mean*100)\n",
    "for mean in cv_test_means:\n",
    "    print(mean)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New figure size\n",
    "fig_size[0] = 15\n",
    "fig_size[1] = 12\n",
    "plt.rcParams[\"figure.figsize\"] = fig_size\n",
    "\n",
    "\n",
    "# For x-axis values \n",
    "cv_axis = list(range(1,11))\n",
    "\n",
    "# Lines to plot\n",
    "plt.plot(k_values, acc_scores, color = \"orange\", linewidth = 4.0, label = \"Testing Accuracy\")\n",
    "plt.plot(k_values, acc_trainscores, color = \"purple\", linewidth = 4.0, label = \"Training Accuracy\")\n",
    "plt.plot(k_values, cv_test_means, color = \"green\", linewidth = 4.0, label = \"10-Fold CV Accuracy\")\n",
    "\n",
    "# Plotting settings \n",
    "plt.title(\"Model 2: K-Nearest Neighbor (metric: minkowski, weight: uniform)\", fontsize = 27)\n",
    "plt.ylabel(\"Accuracy\", fontsize = 25)\n",
    "plt.xlabel(\"K-Value\", fontsize = 25)\n",
    "plt.tick_params(axis = \"both\", which = \"major\", labelsize = 20)\n",
    "\n",
    "# Legend \n",
    "#purple_patch = mpatches.Patch(Color = \"purple\", label = \"Testing\")\n",
    "#orange_patch = mpatches.Patch(Color = \"orange\", label = \"Training\")\n",
    "#green_patch = mpatches.Patch(Color = \"green\", label = \"Validation\")\n",
    "#plt.legend(handles = [orange_patch, purple_patch, green_patch])\n",
    "#handles, labels = ax.get_legend_handles_labels()\n",
    "#ax.legend(handles, labels)\n",
    "plt.legend(fontsize = 20)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 3: KNN  (metric = manhattan  , weight = distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test many k values \n",
    "k_values = [1, 3, 5, 7, 9, 11, 13, 15, 17, 21, 23, 25, 27, 31]\n",
    "print(\"Number of k values: {}\".format(len(k_values)))\n",
    "\n",
    "# Create en empty list to store all data\n",
    "models = []\n",
    "test_predictions = []\n",
    "train_predictions = []\n",
    "confusion_matrices = []\n",
    "class_reports = []\n",
    "acc_scores = []\n",
    "acc_trainscores = []\n",
    "error_scores = []\n",
    "error_scores = []\n",
    "cv_train_scores = []\n",
    "cv_train_means = []\n",
    "cv_train_acc = []\n",
    "cv_test_scores = []\n",
    "cv_test_means = []\n",
    "cv_test_acc = []\n",
    "\n",
    "   \n",
    "for k in k_values:\n",
    "    model = KNeighborsClassifier(n_neighbors = k, metric = \"manhattan\", weights = \"distance\")\n",
    "    models.append(model)\n",
    "print(\"KNN Models:\")\n",
    "for model in models:\n",
    "    print(model)\n",
    "\n",
    "# Fit the model- learn from training set \n",
    "for model in models:\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "# Predict responses on the testing set \n",
    "for model in models:\n",
    "    test_pred = model.predict(X_test)\n",
    "    test_predictions.append(test_pred)\n",
    "    \n",
    "# Predict responses on the training set \n",
    "for model in models:\n",
    "    train_pred = model.predict(X_train)\n",
    "    train_predictions.append(train_pred)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Confusion Matrices:\")\n",
    "\n",
    "# Create confusion matrices for each model \n",
    "for test_pred in test_predictions:\n",
    "    c_matrix = confusion_matrix(y_test, test_pred)\n",
    "    confusion_matrices.append(c_matrix)\n",
    "for c_matrix in confusion_matrices:\n",
    "    print(c_matrix)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Classification Reports:\")\n",
    "    \n",
    "# Create a classificaiton report for each model \n",
    "targets = [\"Edible\", \"Poisonous\"]\n",
    "for test_pred in test_predictions: \n",
    "    report = classification_report(y_test, test_pred, target_names = targets)\n",
    "    class_reports.append(report)\n",
    "for report in class_reports:\n",
    "    print(report)\n",
    "    \n",
    "print(\"\\n\")\n",
    "print(\"Testing Accuracy Scores:\")\n",
    "\n",
    "# Compute the testing accuracy for each model \n",
    "for test_pred in test_predictions:\n",
    "    acc = accuracy_score(y_test, test_pred)\n",
    "    acc_scores.append(acc*100)\n",
    "for acc in acc_scores:\n",
    "    print(acc)\n",
    "    \n",
    "print(\"\\n\")\n",
    "print(\"Training Accuracy Scores:\")\n",
    "\n",
    "for train_pred in train_predictions:\n",
    "    acc = accuracy_score(y_train, train_pred)\n",
    "    acc_trainscores.append(acc*100)\n",
    "for acc in acc_trainscores:\n",
    "    print(acc)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "print(\"\\n\")\n",
    "print(\"Error Scores:\")\n",
    "    \n",
    "    \n",
    "# Compute the testing error for each model \n",
    "for acc in acc_scores:\n",
    "    error = (100 - acc)\n",
    "    error_scores.append(error)\n",
    "for error in error_scores:\n",
    "    print(error)\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "# Perform 10-fold CV to get training and testing scores\n",
    "for model in models:\n",
    "    cv_results = cross_validate(model, X, y, cv = 10, return_train_score = True)\n",
    "    train_score = cv_results[\"train_score\"]\n",
    "    cv_train_scores.append(train_score)\n",
    "    test_score = cv_results[\"test_score\"]\n",
    "    cv_test_scores.append(test_score)\n",
    "    \n",
    "print(\"\\n\")\n",
    "print(\"10-fold CV train scores:\")\n",
    "    \n",
    "for train_score in cv_train_scores:\n",
    "    print(train_score)\n",
    "    \n",
    "print(\"\\n\")\n",
    "print(\"10-fold CV test score:\")\n",
    "for test_score in cv_test_scores:\n",
    "    print(test_score)\n",
    "    \n",
    "\n",
    "#print(\"\\n\")\n",
    "#print(\"10-fold training averages\")\n",
    "# Get means and standard dev from 10-fold CVs\n",
    "for train_score in cv_train_scores:\n",
    "    mean = train_score.mean()\n",
    "    cv_train_means.append(mean)\n",
    "#for mean in cv_train_means:\n",
    "#    print(mean)\n",
    "    \n",
    "    \n",
    "print(\"\\n\") \n",
    "print(\"10-fold testing averages\")\n",
    "\n",
    "for test_score in cv_test_scores:\n",
    "    mean = test_score.mean()\n",
    "    cv_test_means.append(mean*100)\n",
    "for mean in cv_test_means:\n",
    "    print(mean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New figure size\n",
    "fig_size[0] = 15\n",
    "fig_size[1] = 12\n",
    "plt.rcParams[\"figure.figsize\"] = fig_size\n",
    "\n",
    "\n",
    "# For x-axis values \n",
    "cv_axis = list(range(1,11))\n",
    "\n",
    "# Lines to plot\n",
    "plt.plot(k_values, acc_scores, color = \"orange\", linewidth = 4.0, label = \"Testing Accuracy\")\n",
    "plt.plot(k_values, acc_trainscores, color = \"purple\", linewidth = 4.0, label = \"Training Accuracy\")\n",
    "plt.plot(k_values, cv_test_means, color = \"green\", linewidth = 4.0, label = \"10-Fold CV Accuracy\")\n",
    "\n",
    "# Plotting settings \n",
    "plt.title(\"Model 3: K-Nearest Neighbor (metric: manhattan, weight: distance)\", fontsize = 27)\n",
    "plt.ylabel(\"Accuracy\", fontsize = 25)\n",
    "plt.xlabel(\"K-Value\", fontsize = 25)\n",
    "plt.tick_params(axis = \"both\", which = \"major\", labelsize = 20)\n",
    "\n",
    "# Legend \n",
    "#purple_patch = mpatches.Patch(Color = \"purple\", label = \"Testing\")\n",
    "#orange_patch = mpatches.Patch(Color = \"orange\", label = \"Training\")\n",
    "#green_patch = mpatches.Patch(Color = \"green\", label = \"Validation\")\n",
    "#plt.legend(handles = [orange_patch, purple_patch, green_patch])\n",
    "#handles, labels = ax.get_legend_handles_labels()\n",
    "#ax.legend(handles, labels)\n",
    "plt.legend(fontsize = 20)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = sns.heatmap(confusion_matrix, square = True, \n",
    "                xticklabels = ['e', 'p'], \n",
    "                annot = True, \n",
    "                annot_kws = {'fontsize': 12}, \n",
    "                yticklabels = ['e', 'p'], \n",
    "                cbar = True, \n",
    "                cbar_kws = {\"orientation\": \"horizontal\"}, \n",
    "                cmap = \"Blues\").set(xlabel = \"predicted\", \n",
    "                ylabel = \"true\", title = 'Confusion Matrix')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
